{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZqUDEx320Q3ivai3IspGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sergey-Kiselev-dev/ML_sem_pub/blob/main/ML_02_selfedu_nn_20a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "fdFv4gurBZw0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"﻿Думайте позитивно и верьте в свою способность достигать отличных результатов.\n",
        "Вы — лучший ответ на проблемы, которые возникли в понедельник.\n",
        "Если вы смогли в понедельник подняться с постели, значит вы супер герой.\n",
        "Твои утренние мысли в понедельник задают тон всей твоей неделе.\n",
        "Живи так чтобы увидеть, как ты становишься сильнее и живешь счастливой, полноценной жизнью.\n",
        "Не позволяйте утренним проблемам помешать вам быть успешным.\n",
        "Тяжелые времена часто приводят к величайшим моментам вашей жизни.\n",
        "Продолжайте двигаться. Трудности в конце концов создают сильных людей.\n",
        "Независимо через что вы проходите, в конце туннеля есть свет. Может показаться, что добраться до него сложно, но вы сможете сделать это.\n",
        "Чем больше вы настроены позитивно и говорите: я хочу иметь хорошую жизнь, тем больше вы строите для себя эту реальность.\n",
        "Принятие позитивного отношения ко всему происходящему может творить чудеса.\n",
        "Хорошее настроение добавляет годы к вашей жизни, весну к вашему шагу, искорку в ваших глазах.\n",
        "Природные способности важны, но вы можете многого достичь и без них, если у вас есть целеустремленность.\n",
        "Окружите себя позитивными людьми, которые верят в ваши мечты, поддерживают ваши идеи.\n",
        "Оставайся позитивным. Прости других. Инвестируй в себя. Доверяй своим инстинктам.\n",
        "Не позволяй другим испортить твой день. Делай вещи, которые приносят тебе радость. Люби себя.\n",
        "Иногда лучшее, что ты можешь сделать — это не думать, не удивляться, не воображать, не зацикливаться.\n",
        "Просто дыши и верь, что все получится к лучшему.\n",
        "Не просто учись, а приобретай опыт; не читай, а впитывай. Не просто меняйся, а трансформируйся; не просто связывай, а защищай; не обещай, а докажи.\n",
        "Не критикуй, а поощряй; не просто возьми, а дай; не просто увидь, а почувствуй.\n",
        "Не просто мечтай, а делай; не достаточно услышать, а слушай; не просто расскажи, а покажи.\n",
        "Преданность, вера и позитивное отношение — все это важно, если вы собираетесь добиться успеха.\n",
        "Выбор позитивного настроя и благодарного отношения определит, как вы собираетесь прожить свою жизнь.\n",
        "Для меня жизнь заключается в том, чтобы быть позитивным и обнадеживающим, выбирая радость.\n",
        "Вы можете сделать позитивный выбор на всю оставшуюся жизнь.\n",
        "Не тратьте свое время на гнев, сожаления, беспокойства и обиды.\n",
        "Жизнь слишком коротка, чтобы быть несчастной.\n",
        "Всегда верьте в себя и выходите за пределы своих возможностей.\n",
        "Ваша жизнь стоит намного больше, чем думаете, потому что вы способны достичь большего, чем знаете.\n",
        "У вас больше потенциала, чем вам кажется. Но вряд ли вы узнаете весь свой потенциал, если не будете бросать себе вызов.\n",
        "Живи каждый день так, словно твоя жизнь только началась.\n",
        "Если вы просто посмотрите на жизнь позитивно, произойдут позитивные вещи.\n",
        "Жизнь становится легче и прекраснее, когда мы видим добро в других людях.\n",
        "Я беру все негативы в своей жизни и превращаю их в позитив.\n",
        "Держись за свои мечты о лучшей жизни и оставайся приверженным стремлению реализовать это.\n",
        "Вы не можете жить позитивной жизнью с негативным умом.\n",
        "Чтобы иметь положительный результат нужно только больше позитива, а от всего остального просто отшутиться.\n",
        "Мы все можем привнести позитивную энергию в нашу повседневную жизнь.\n",
        "Если будем больше улыбаться, разговаривать с незнакомцами, заменять рукопожатия объятиями и звонить друзьям, просто чтобы сказать им, что мы их любим.\n",
        "Чем меньше вы реагируете на негативных людей, тем более позитивной станет ваша жизнь.\n",
        "Когда вы контролируете свое отношение, вы контролируете свою жизнь.\n",
        "Сфокусируйтесь на своих сильных сторонах, а не на слабостях.\n",
        "Сосредоточьтесь на своей личности, а не на своей репутации, на своих благословениях, а не на несчастьях.\n",
        "Будьте позитивны с каждой идеей, питающей ваши мечты.\n",
        "Подумайте о возможности того, что вы планируете делать, и подойдите к этому с оптимизмом.\n",
        "Оставайтесь на позитиве.\n",
        "Вы уникальны! У вас разные таланты и способности. Вам не нужно всегда идти по стопам других.\n",
        "Всегда напоминайте себе, что вам не нужно делать то, что делают все остальные.\n",
        "Вы должны развивать таланты, которые были вам даны.\n",
        "Старайтесь сделать хорошие дни великими и взять что-то положительное из тех дней, когда не чувствуете себя хорошо.\n",
        "Будьте позитивным человеком и продолжайте двигаться вперед.\n",
        "Когда вы просыпаетесь, у вас есть два варианта: быть положительным или отрицательным, оптимистом или пессимистом.\n",
        "Практически нет ничего невозможного в этом мире, если вы просто сосредоточитесь на цели и сохраните позитивный настрой.\n",
        "На мгновение отвлекись от проблем и сосредоточься на положительных возможностях.\n",
        "Подумай, как много ты можешь сделать.\n",
        "Победители в преддверии мероприятия имеют привычку выдвигать свои собственные позитивные ожидания.\n",
        "Работай усердно ради того, чего хочешь, потому что оно не придет к тебе без боя.\n",
        "Ты должен быть сильным и смелым, зная, что можешь делать все, что задумал.\n",
        "Если кто-то тебя критикует, просто продолжай верить в себя и превращай это во что-то позитивное.\n",
        "Самая большая стена, на которую вам нужно подняться — это та, которую вы строите в своем уме.\n",
        "Никогда не позволяйте своему разуму отговорить вас от мечты и обманом заставить вас сдаться.\n",
        "Не позволяйте ему стать величайшим препятствием на вашем пути к успеху.\n",
        "Ничто не делает человека счастливее, чем счастливое сердце.\n",
        "Скажите и сделайте нечто позитивное, желая помочь ситуации. Чтобы жаловаться, мозги не нужны.\n",
        "Изменения не всегда приносят рост, но без изменений нет роста.\n",
        "Никогда не фокусируйтесь на негативе, а всегда смотрите на позитив.\n",
        "Всегда превращай счастье, боль, печаль и слезы в позитивную энергию.\n",
        "Либо ты бежишь день, либо день бежит за тобой.\n",
        "Будь позитивным и смейся над всем.\n",
        "Каждый день живи с позитивным настроем и пытайся улучшиться.\n",
        "Позитивное всё — лучше, чем негативное ничего.\n",
        "Никто не идеален — вот почему у карандашей есть ластики.\n",
        "Позитивность всегда побеждает мудрость.\n",
        "Самое главное — смотреть в будущее. Прошлое — это твой якорь.\n",
        "В глубине своего сердца верьте, что вам суждено совершать великие дела.\n",
        "Чудеса рождаются из убеждений.\n",
        "Одна вещь за один раз. Сначала самое главное. Начинай сейчас.\n",
        "Мы ограничены, но мы можем раздвинуть границы наших ограничений.\n",
        "Пусть позитив будет вашим вторым именем. Ваша позитивность станет щитом вокруг вас, который защитит вас от стрелы негатива.\n",
        "Если вы настроены позитивно, то увидите возможности, а не препятствия.\n",
        "Позитивное мышление и визуализация моего успеха были моими ключами к успеху.\n",
        "Только хорошее действие в сочетании с позитивным мышлением приводит к успеху.\n",
        "Чтобы создать радугу, нужны солнечный свет и дождь, а без них не было бы радуги.\n",
        "Худшие времена могут стать лучшими, если вы думаете о них с хорошим настроем.\"\"\"\n",
        "text = text.replace('\\ufeff', '')  # убираем первый невидимый символ\n",
        "text = text.replace('.', ' ')\n",
        "text = re.sub(r'[^А-я ]', '', text)  # заменяем все символы кроме кириллицы на пустые символы\n",
        "text = text.replace('  ', ' ')\n",
        "print(text)"
      ],
      "metadata": {
        "id": "d3ONyCv2CGuj",
        "outputId": "6156702a-fd42-421f-8d91-055e6354a2c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Думайте позитивно и верьте в свою способность достигать отличных результатов Вы лучший ответ на проблемы которые возникли в понедельник Если вы смогли в понедельник подняться с постели значит вы супер герой Твои утренние мысли в понедельник задают тон всей твоей неделе Живи так чтобы увидеть как ты становишься сильнее и живешь счастливой полноценной жизнью Не позволяйте утренним проблемам помешать вам быть успешным Тяжелые времена часто приводят к величайшим моментам вашей жизни Продолжайте двигаться Трудности в конце концов создают сильных людей Независимо через что вы проходите в конце туннеля есть свет Может показаться что добраться до него сложно но вы сможете сделать это Чем больше вы настроены позитивно и говорите я хочу иметь хорошую жизнь тем больше вы строите для себя эту реальность Принятие позитивного отношения ко всему происходящему может творить чудеса Хорошее настроение добавляет годы к вашей жизни весну к вашему шагу искорку в ваших глазах Природные способности важны но вы можете многого достичь и без них если у вас есть целеустремленность Окружите себя позитивными людьми которые верят в ваши мечты поддерживают ваши идеи Оставайся позитивным Прости других Инвестируй в себя Доверяй своим инстинктам Не позволяй другим испортить твой день Делай вещи которые приносят тебе радость Люби себя Иногда лучшее что ты можешь сделать это не думать не удивляться не воображать не зацикливаться Просто дыши и верь что все получится к лучшему Не просто учись а приобретай опыт не читай а впитывай Не просто меняйся а трансформируйся не просто связывай а защищай не обещай а докажи Не критикуй а поощряй не просто возьми а дай не просто увидь а почувствуй Не просто мечтай а делай не достаточно услышать а слушай не просто расскажи а покажи Преданность вера и позитивное отношение все это важно если вы собираетесь добиться успеха Выбор позитивного настроя и благодарного отношения определит как вы собираетесь прожить свою жизнь Для меня жизнь заключается в том чтобы быть позитивным и обнадеживающим выбирая радость Вы можете сделать позитивный выбор на всю оставшуюся жизнь Не тратьте свое время на гнев сожаления беспокойства и обиды Жизнь слишком коротка чтобы быть несчастной Всегда верьте в себя и выходите за пределы своих возможностей Ваша жизнь стоит намного больше чем думаете потому что вы способны достичь большего чем знаете У вас больше потенциала чем вам кажется Но вряд ли вы узнаете весь свой потенциал если не будете бросать себе вызов Живи каждый день так словно твоя жизнь только началась Если вы просто посмотрите на жизнь позитивно произойдут позитивные вещи Жизнь становится легче и прекраснее когда мы видим добро в других людях Я беру все негативы в своей жизни и превращаю их в позитив Держись за свои мечты о лучшей жизни и оставайся приверженным стремлению реализовать это Вы не можете жить позитивной жизнью с негативным умом Чтобы иметь положительный результат нужно только больше позитива а от всего остального просто отшутиться Мы все можем привнести позитивную энергию в нашу повседневную жизнь Если будем больше улыбаться разговаривать с незнакомцами заменять рукопожатия объятиями и звонить друзьям просто чтобы сказать им что мы их любим Чем меньше вы реагируете на негативных людей тем более позитивной станет ваша жизнь Когда вы контролируете свое отношение вы контролируете свою жизнь Сфокусируйтесь на своих сильных сторонах а не на слабостях Сосредоточьтесь на своей личности а не на своей репутации на своих благословениях а не на несчастьях Будьте позитивны с каждой идеей питающей ваши мечты Подумайте о возможности того что вы планируете делать и подойдите к этому с оптимизмом Оставайтесь на позитиве Вы уникальны У вас разные таланты и способности Вам не нужно всегда идти по стопам других Всегда напоминайте себе что вам не нужно делать то что делают все остальные Вы должны развивать таланты которые были вам даны Старайтесь сделать хорошие дни великими и взять чтото положительное из тех дней когда не чувствуете себя хорошо Будьте позитивным человеком и продолжайте двигаться вперед Когда вы просыпаетесь у вас есть два варианта быть положительным или отрицательным оптимистом или пессимистом Практически нет ничего невозможного в этом мире если вы просто сосредоточитесь на цели и сохраните позитивный настрой На мгновение отвлекись от проблем и сосредоточься на положительных возможностях Подумай как много ты можешь сделать Победители в преддверии мероприятия имеют привычку выдвигать свои собственные позитивные ожидания Работай усердно ради того чего хочешь потому что оно не придет к тебе без боя Ты должен быть сильным и смелым зная что можешь делать все что задумал Если ктото тебя критикует просто продолжай верить в себя и превращай это во чтото позитивное Самая большая стена на которую вам нужно подняться это та которую вы строите в своем уме Никогда не позволяйте своему разуму отговорить вас от мечты и обманом заставить вас сдаться Не позволяйте ему стать величайшим препятствием на вашем пути к успеху Ничто не делает человека счастливее чем счастливое сердце Скажите и сделайте нечто позитивное желая помочь ситуации Чтобы жаловаться мозги не нужны Изменения не всегда приносят рост но без изменений нет роста Никогда не фокусируйтесь на негативе а всегда смотрите на позитив Всегда превращай счастье боль печаль и слезы в позитивную энергию Либо ты бежишь день либо день бежит за тобой Будь позитивным и смейся над всем Каждый день живи с позитивным настроем и пытайся улучшиться Позитивное вс лучше чем негативное ничего Никто не идеален вот почему у карандашей есть ластики Позитивность всегда побеждает мудрость Самое главное смотреть в будущее Прошлое это твой якорь В глубине своего сердца верьте что вам суждено совершать великие дела Чудеса рождаются из убеждений Одна вещь за один раз Сначала самое главное Начинай сейчас Мы ограничены но мы можем раздвинуть границы наших ограничений Пусть позитив будет вашим вторым именем Ваша позитивность станет щитом вокруг вас который защитит вас от стрелы негатива Если вы настроены позитивно то увидите возможности а не препятствия Позитивное мышление и визуализация моего успеха были моими ключами к успеху Только хорошее действие в сочетании с позитивным мышлением приводит к успеху Чтобы создать радугу нужны солнечный свет и дождь а без них не было бы радуги Худшие времена могут стать лучшими если вы думаете о них с хорошим настроем \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('train_data_true', 'r', encoding='utf-8') as f:\n",
        "    # text = f.read()\n",
        "    # text = text.replace('\\ufeff', '')  # убираем первый невидимый символ\n",
        "    # text = re.sub(r'[^А-я ]', '', text)  # заменяем все символы кроме кириллицы на пустые символы\n",
        "\n",
        "# парсим текст, как последовательность символов\n",
        "num_characters = 34  # 33 буквы + пробел\n",
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)  # токенизируем на уровне символов\n",
        "tokenizer.fit_on_texts([text])  # формируем токены на основе частотности в нашем тексте\n",
        "print(tokenizer.word_index)\n",
        "\n",
        "inp_chars = 6\n",
        "data = tokenizer.texts_to_matrix(text)  # преобразуем исходный текст в массив OHE\n",
        "n = data.shape[0] - inp_chars  # так как мы предсказываем по трем символам - четвертый\n",
        "\n",
        "X = np.array([data[i:i + inp_chars, :] for i in range(n)])\n",
        "Y = data[inp_chars:]  # предсказание следующего символа\n",
        "\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "Dm8P3ajcBkBa",
        "outputId": "959e4238-ad44-4884-9a96-a21121205b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'о': 2, 'е': 3, 'т': 4, 'и': 5, 'а': 6, 'н': 7, 'с': 8, 'в': 9, 'р': 10, 'м': 11, 'л': 12, 'ь': 13, 'д': 14, 'п': 15, 'у': 16, 'ы': 17, 'з': 18, 'я': 19, 'б': 20, 'ч': 21, 'к': 22, 'й': 23, 'ж': 24, 'г': 25, 'ш': 26, 'х': 27, 'ю': 28, 'ц': 29, 'щ': 30, 'э': 31, 'ф': 32, 'ъ': 33}\n",
            "(6380, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_chars,\n",
        "                 num_characters)))  # при тренировке в рекуррентные модели keras подается сразу вся последовательность, поэтому в input теперь два числа. 1-длина последовательности, 2-размер OHE\n",
        "model.add(SimpleRNN(128, activation='tanh'))  # рекуррентный слой на 500 нейронов\n",
        "model.add(Dense(num_characters, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "history = model.fit(X, Y, batch_size=32, epochs=100)\n",
        "\n",
        "\n",
        "def buildPhrase(inp_str, str_len=50):\n",
        "    for i in range(str_len):\n",
        "        x = []\n",
        "        for j in range(i, i + inp_chars):\n",
        "            x.append(tokenizer.texts_to_matrix(inp_str[j]))  # преобразуем символы в One-Hot-encoding\n",
        "\n",
        "        x = np.array(x)\n",
        "        inp = x.reshape(1, inp_chars, num_characters)\n",
        "\n",
        "        pred = model.predict(inp)  # предсказываем OHE четвертого символа\n",
        "        d = tokenizer.index_word[pred.argmax(axis=1)[0]]  # получаем ответ в символьном представлении\n",
        "\n",
        "        inp_str += d  # дописываем строку\n",
        "\n",
        "    return inp_str\n",
        "\n",
        "\n",
        "res = buildPhrase(\"утренн\")\n",
        "print(res)"
      ],
      "metadata": {
        "id": "op9sbOyABlPK",
        "outputId": "a92f1eec-0168-4364-f9ff-4670b167f79c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 128)               20864     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 34)                4386      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25250 (98.63 KB)\n",
            "Trainable params: 25250 (98.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "200/200 [==============================] - 4s 7ms/step - loss: 2.9521 - accuracy: 0.1867\n",
            "Epoch 2/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 2.5962 - accuracy: 0.2727\n",
            "Epoch 3/100\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 2.4073 - accuracy: 0.3166\n",
            "Epoch 4/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 2.2759 - accuracy: 0.3386\n",
            "Epoch 5/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 2.1793 - accuracy: 0.3651\n",
            "Epoch 6/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 2.1119 - accuracy: 0.3816\n",
            "Epoch 7/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 2.0520 - accuracy: 0.3924\n",
            "Epoch 8/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 2.0002 - accuracy: 0.4081\n",
            "Epoch 9/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.9556 - accuracy: 0.4192\n",
            "Epoch 10/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.9146 - accuracy: 0.4314\n",
            "Epoch 11/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.8756 - accuracy: 0.4402\n",
            "Epoch 12/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.8351 - accuracy: 0.4459\n",
            "Epoch 13/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.7926 - accuracy: 0.4548\n",
            "Epoch 14/100\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 1.7583 - accuracy: 0.4729\n",
            "Epoch 15/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 1.7159 - accuracy: 0.4871\n",
            "Epoch 16/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 1.6788 - accuracy: 0.4918\n",
            "Epoch 17/100\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 1.6386 - accuracy: 0.5009\n",
            "Epoch 18/100\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 1.5934 - accuracy: 0.5140\n",
            "Epoch 19/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.5633 - accuracy: 0.5242\n",
            "Epoch 20/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.5176 - accuracy: 0.5325\n",
            "Epoch 21/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.4773 - accuracy: 0.5483\n",
            "Epoch 22/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.4382 - accuracy: 0.5590\n",
            "Epoch 23/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.4015 - accuracy: 0.5725\n",
            "Epoch 24/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.3646 - accuracy: 0.5758\n",
            "Epoch 25/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.3274 - accuracy: 0.5916\n",
            "Epoch 26/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.2941 - accuracy: 0.6013\n",
            "Epoch 27/100\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 1.2650 - accuracy: 0.6101\n",
            "Epoch 28/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.2294 - accuracy: 0.6164\n",
            "Epoch 29/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.1950 - accuracy: 0.6315\n",
            "Epoch 30/100\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 1.1611 - accuracy: 0.6472\n",
            "Epoch 31/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 1.1373 - accuracy: 0.6450\n",
            "Epoch 32/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 1.0959 - accuracy: 0.6585\n",
            "Epoch 33/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 1.0733 - accuracy: 0.6705\n",
            "Epoch 34/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.0334 - accuracy: 0.6848\n",
            "Epoch 35/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 1.0128 - accuracy: 0.6814\n",
            "Epoch 36/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.9777 - accuracy: 0.6977\n",
            "Epoch 37/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.9504 - accuracy: 0.7077\n",
            "Epoch 38/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.9287 - accuracy: 0.7142\n",
            "Epoch 39/100\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.9065 - accuracy: 0.7256\n",
            "Epoch 40/100\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.8811 - accuracy: 0.7267\n",
            "Epoch 41/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.8499 - accuracy: 0.7380\n",
            "Epoch 42/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.8352 - accuracy: 0.7427\n",
            "Epoch 43/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.8129 - accuracy: 0.7502\n",
            "Epoch 44/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.7835 - accuracy: 0.7584\n",
            "Epoch 45/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.7646 - accuracy: 0.7672\n",
            "Epoch 46/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.7432 - accuracy: 0.7735\n",
            "Epoch 47/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.7247 - accuracy: 0.7813\n",
            "Epoch 48/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.7164 - accuracy: 0.7830\n",
            "Epoch 49/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.6916 - accuracy: 0.7877\n",
            "Epoch 50/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.6747 - accuracy: 0.7909\n",
            "Epoch 51/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.6568 - accuracy: 0.7986\n",
            "Epoch 52/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.6445 - accuracy: 0.8020\n",
            "Epoch 53/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.6267 - accuracy: 0.8083\n",
            "Epoch 54/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.6175 - accuracy: 0.8088\n",
            "Epoch 55/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.5993 - accuracy: 0.8172\n",
            "Epoch 56/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.5783 - accuracy: 0.8279\n",
            "Epoch 57/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.5754 - accuracy: 0.8240\n",
            "Epoch 58/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.5615 - accuracy: 0.8268\n",
            "Epoch 59/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.5469 - accuracy: 0.8337\n",
            "Epoch 60/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.5360 - accuracy: 0.8384\n",
            "Epoch 61/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.5268 - accuracy: 0.8395\n",
            "Epoch 62/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.5268 - accuracy: 0.8408\n",
            "Epoch 63/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.5030 - accuracy: 0.8484\n",
            "Epoch 64/100\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.4969 - accuracy: 0.8514\n",
            "Epoch 65/100\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.4849 - accuracy: 0.8522\n",
            "Epoch 66/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4874 - accuracy: 0.8497\n",
            "Epoch 67/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4841 - accuracy: 0.8500\n",
            "Epoch 68/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4712 - accuracy: 0.8486\n",
            "Epoch 69/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4563 - accuracy: 0.8634\n",
            "Epoch 70/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4551 - accuracy: 0.8629\n",
            "Epoch 71/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4459 - accuracy: 0.8623\n",
            "Epoch 72/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4429 - accuracy: 0.8662\n",
            "Epoch 73/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4471 - accuracy: 0.8632\n",
            "Epoch 74/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4360 - accuracy: 0.8654\n",
            "Epoch 75/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4214 - accuracy: 0.8703\n",
            "Epoch 76/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.4186 - accuracy: 0.8679\n",
            "Epoch 77/100\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.8674\n",
            "Epoch 78/100\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.4318 - accuracy: 0.8685\n",
            "Epoch 79/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4066 - accuracy: 0.8739\n",
            "Epoch 80/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4078 - accuracy: 0.8721\n",
            "Epoch 81/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.4104 - accuracy: 0.8729\n",
            "Epoch 82/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3986 - accuracy: 0.8773\n",
            "Epoch 83/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3862 - accuracy: 0.8805\n",
            "Epoch 84/100\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.3945 - accuracy: 0.8756\n",
            "Epoch 85/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3947 - accuracy: 0.8784\n",
            "Epoch 86/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3831 - accuracy: 0.8767\n",
            "Epoch 87/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.8742\n",
            "Epoch 88/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3774 - accuracy: 0.8797\n",
            "Epoch 89/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3832 - accuracy: 0.8759\n",
            "Epoch 90/100\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.8779\n",
            "Epoch 91/100\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.3784 - accuracy: 0.8776\n",
            "Epoch 92/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.3652 - accuracy: 0.8841\n",
            "Epoch 93/100\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.3716 - accuracy: 0.8836\n",
            "Epoch 94/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3554 - accuracy: 0.8866\n",
            "Epoch 95/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3671 - accuracy: 0.8787\n",
            "Epoch 96/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3671 - accuracy: 0.8822\n",
            "Epoch 97/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3596 - accuracy: 0.8805\n",
            "Epoch 98/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3519 - accuracy: 0.8852\n",
            "Epoch 99/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3474 - accuracy: 0.8896\n",
            "Epoch 100/100\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3527 - accuracy: 0.8910\n",
            "1/1 [==============================] - 0s 203ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "утренние мысли в понедельник если вы проходите за предел\n"
          ]
        }
      ]
    }
  ]
}